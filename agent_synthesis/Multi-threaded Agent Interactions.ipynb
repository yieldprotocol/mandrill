{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c70ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import random\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import pdfkit\n",
    "import html\n",
    "from copy import deepcopy\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import time  # Used for simulating API call\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0acec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# setting up an OpenAI template on the run\n",
    "OPENAI_API_KEY = getpass()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a4c6c",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ded2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4-0613\")\n",
    "model.temperature = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4de532",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10bb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_prompt_template = '''\n",
    "You will simulate a software enviroment that can be used by a user or agent. You will simulate the following software environment:\n",
    "{}\n",
    "\n",
    "The following information explains the expectations about inputs and outputs of the environment:\n",
    "{}\n",
    "\n",
    "You should do your absolute best to interact with the user as if you are the given environment. You should NOT act as if you are chatGPT, GPT-4, or any other AI agent. The goal is to make a convincing simulation. Below you are given information about the state of the environment:\n",
    "{}\n",
    "\n",
    "When acting as the environment, you may make up any data or information you need, as long as it is consistent with the state and the user actions. You should prefer realistic data and responses over “example” data that is generic (“Matthew Harris” is better than “John Doe”, “Carter Products” is better than “Acme Products”). Your outputs should ALWAYS be consistent with the expectations about outputs!\n",
    "\n",
    "In any situation where the inputs from the user are incomplete, unrecognized, or not as per the expected format for the software environment, you should return an error and generic information about how inputs of the given type may be presented. \n",
    "\n",
    "Please start with an opening message from the software environment to the user with a basic explanation of how to begin using the software environment.\n",
    "'''\n",
    "\n",
    "\n",
    "agent_prompt_template = '''\n",
    "Interact with a software environment to solve a task. Imagine you are an intelligent agent working for a user and your target is to perform actions to complete the task goal. At the beginning of your interactions, you will be given a detailed description of the current environment and your goal to accomplish. For each of your turns, you will be given a list of actions which you can choose one to perform in this turn. You should provide two parts of your response: \"THOUGHT\" and \"ACTION\". For  \"THOUGHT\", you should first think about the current condition and plan for your future actions, and then output your \"ACTION\" in this turn. Your output must strictly follow this format:\"THOUGHT: your thoughts.\n",
    " ACTION: your next action \n",
    "\"; For \"ACTION\", you should directly output the action this turn. Your output must strictly follow this format:\"ACTION: your next action\n",
    "\". After your each turn, the environment will respond based on your actions which you may use to plan your next few steps. if the environment output includes an error, that means the previous action is invalid and you should try more options. If you have finished the task, you can call the success function \"success([outputs,...])\" with any final outputs.\n",
    " Reminder: \n",
    "1. the action must follow any formats requested\n",
    "2. Think when necessary, try to act directly more in the process.\n",
    "If information is requested that you don't have, you may use placeholder information, but please note the information when calling \"success()\". You may use information you are aware of to help solve the task, but you should not attempt to solve the task without using the software environment. \n",
    "\n",
    "Software Environment: {}\n",
    "Your Task: {}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc127aef",
   "metadata": {},
   "source": [
    "### Setup Interaction Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa071ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_conversation(task):    \n",
    "    num_turns = 20\n",
    "    the_task = task['task']\n",
    "    the_state = task['state']\n",
    "    print(\"Task:\", the_task)\n",
    "    environment_prompt = environment_prompt_template.format(task['environment'], task['io'], task['state'])\n",
    "    agent_prompt = agent_prompt_template.format(task['environment'], task['task'])\n",
    "    agent_messages = [\n",
    "        HumanMessage(content=agent_prompt),\n",
    "    ]\n",
    "\n",
    "    environment_messages = [\n",
    "        HumanMessage(content=environment_prompt)\n",
    "    ]\n",
    "\n",
    "    for i in range(num_turns):\n",
    "        environment_result = model.predict_messages(environment_messages)\n",
    "        environment_messages.append(environment_result)\n",
    "        agent_messages.append(HumanMessage(content=environment_result.content))\n",
    "        agent_response = model.predict_messages(agent_messages)\n",
    "        agent_result = agent_response.content.split(\"ACTION:\")[1].strip()\n",
    "        environment_messages.append(HumanMessage(content=agent_result))\n",
    "        agent_messages.append(agent_response)\n",
    "        if \"success(\" in agent_result:\n",
    "            break\n",
    "    task[\"conversation\"] = agent_messages\n",
    "    return task\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48611898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker function\n",
    "def api_worker(input_queue, output_queue):\n",
    "    global stop_threads\n",
    "    while not stop_threads:\n",
    "        try:\n",
    "            data = input_queue.get(timeout=1)\n",
    "            updated_data = create_agent_conversation(data)\n",
    "            output_queue.put(updated_data)\n",
    "            \n",
    "            # Mark task as done\n",
    "            input_queue.task_done()\n",
    "        except queue.Empty:\n",
    "            # No more items in queue\n",
    "            return\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Received interrupt in worker. Re-queueing item...\")\n",
    "            input_queue.put(data)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # Handle other exceptions as required\n",
    "            print(f\"Error processing data: {e}\")\n",
    "            input_queue.put(data)  # Re-insert the item into the queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9051de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_queue_to_file(q, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(list(q.queue), file)\n",
    "\n",
    "def load_queue_from_file(filename):\n",
    "    try:\n",
    "        q = queue.Queue()\n",
    "        with open(filename, 'rb') as file:\n",
    "            the_list = pickle.load(file)\n",
    "            for item in the_list:\n",
    "                q.put(item)\n",
    "        return q\n",
    "    except (FileNotFoundError, EOFError):\n",
    "        return queue.Queue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73844d",
   "metadata": {},
   "source": [
    "### Run Multi-threaded Agent Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181e97f",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4113370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Load existing multi-threaded Agent Interactions file that we will add new interactions to\n",
    "# Make sure to use the correct path to your .pkl file\n",
    "file_path = \"./synthetic/synthetic_agent_conversations.pkl\"\n",
    "\n",
    "# Open the file and load its contents into resulting_dicts\n",
    "with open(file_path, 'rb') as file:\n",
    "    resulting_dicts = pickle.load(file)\n",
    "\n",
    "# Now resulting_dicts contains the data from the .pkl file\n",
    "print(len(resulting_dicts))  # Just to verify the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "151a80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input queue is the list of tasks that haven't yet been turned into agent interactions\n",
    "input_queue = load_queue_from_file(\"./synthetic/input_queue.pkl\")\n",
    "output_queue = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b69377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_queue.qsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961c55f",
   "metadata": {},
   "source": [
    "#### Run Multi-threaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f377c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of threads\n",
    "NUM_THREADS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8170b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:Task: Doctor Ava Thomas needs to revise the diagnosis for patient James White who was incorrectly diagnosed with gastroenteritis.\n",
      "Task: Simulate a chromosomal DNA sequence with a length of 8 million bases, using the Oxford Nanopore sequencing technology with a mutation rate of 0.0003.\n",
      " Run an electromagnetic interference analysis for an automotive radar system\n",
      "Error processing data: list index out of range\n",
      "Task: Calculate the average transaction amount in USD for all entries in the 'Sales' dataset for the month of July.\n",
      "Task: Create a unit test for a function 'calculateDiscount' in a pricing module of an e-commerce platform\n",
      "Task: Analyze the environmental impact of a 1-year project to restore coral reefs in the Great Barrier Reef using lab-grown corals.\n",
      "Task: Return 'The Hobbit' borrowed by user Richard West.\n",
      "Task: Simulate a chromosomal DNA sequence with a length of 10 million bases, using the Oxford Nanopore sequencing technology with a mutation rate of 0.0004.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Update the property details for a studio apartment in San Francisco listed by broker Lydia Morton, changing the bathroom count from 1 to 1.5.\n",
      "Task: Try to increase the inventory by finding new items\n",
      "Task: Simulate the DNA sequence of mitochondrial DNA with a length of 21000 bases, with a region of interest from 10000 to 11000, using the Illumina sequencing technology with a mutation rate of 0.002.\n",
      "Task: Test the performance of the newly adjusted algorithm for the fractional knapsack problem.\n",
      "Task: Read the results of a previously executed simulation to understand the impact of lead shielding on gamma-ray doses\n",
      "Task: Modify the Colpitts oscillator designed by James Kim, by changing the inductor value to 1mH. Run a frequency sweep to observe the changes in resonant frequency.\n",
      "Task: Introduce a new food stall selling vegan food.\n",
      "Task: Fetch the current fuel status for Captain Garcia\n",
      "Task: Close Ticket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Suspend the process 'proc2' temporarily\n",
      "Task: Optimize the design of a dipole antenna for a specific impedance\n",
      "Task: Follow a pre-determined path with drone X876 through a dense forest using the 'follow_path' command\n",
      "Task: Calculate the bandwidth of a Yagi-Uda antenna operating at a frequency of 900 MHz\n",
      "\n",
      "Received keyboard interrupt. Signaling threads to terminate...\n",
      "All threads have finished.\n"
     ]
    }
   ],
   "source": [
    "# Launch threads, when you want to stop, use Kernal>Interrupt and wait for it to complete current work\n",
    "threads = []\n",
    "stop_threads = False\n",
    "for _ in range(NUM_THREADS):\n",
    "    t = threading.Thread(target=api_worker, args=(input_queue, output_queue))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "try:\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nReceived keyboard interrupt. Signaling threads to terminate...\")\n",
    "    stop_threads = True\n",
    "\n",
    "    # Now wait for all threads to finish\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "print(\"All threads have finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1895817f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "# Collect results\n",
    "# resulting_dicts = []\n",
    "while not output_queue.empty():\n",
    "    resulting_dicts.append(output_queue.get())\n",
    "\n",
    "print(len(resulting_dicts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b2337",
   "metadata": {},
   "source": [
    "#### Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "feadc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new agent interactions\n",
    "with open(\"./synthetic/synthetic_agent_conversations.pkl\", 'wb') as file:\n",
    "    pickle.dump(resulting_dicts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc566314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save current state of the input queue\n",
    "save_queue_to_file(input_queue, \"./synthetic/input_queue.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7332b20f",
   "metadata": {},
   "source": [
    "### Print Agent Interactions to PDF for easy viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfe8018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "def format_single_chat(chat_data):\n",
    "    formatted_html = '<div style=\"border: 1px solid #ddd; padding: 10px; max-width: 1000px; margin-bottom: 20px;\">'\n",
    "\n",
    "    # Add task as a header\n",
    "    formatted_html += f'<h2>Task: {html.escape(chat_data[\"task\"])}</h2>'\n",
    "\n",
    "    # Add environment, io, and state with a smaller font on a neutral background\n",
    "    formatted_html += (\n",
    "        '<div style=\"background-color: #f7f7f7; padding: 10px; border-radius: 5px; font-size: 0.9em;\">'\n",
    "        f'<strong>Environment:</strong> {html.escape(chat_data[\"environment\"])}<br>'\n",
    "        f'<strong>IO:</strong> {html.escape(chat_data[\"io\"])}<br>'\n",
    "        f'<strong>State:</strong> {html.escape(chat_data[\"state\"])}'\n",
    "        '</div>'\n",
    "    )\n",
    "\n",
    "    # Loop through the conversation\n",
    "    for message in chat_data[\"conversation\"]:\n",
    "        # Depending on the message origin, use a different background color\n",
    "        bg_color = \"#f0f0f0\" if message.__class__.__name__ == \"HumanMessage\" else \"#d1e7fd\"\n",
    "        escaped_text = html.escape(message.content.strip())\n",
    "\n",
    "        formatted_html += (\n",
    "            f'<div style=\"background-color: {bg_color}; padding: 20px; '\n",
    "            'border-radius: 5px; margin: 20px 0;\">'\n",
    "            f'<strong>{message.__class__.__name__.replace(\"Message\", \"\")}:</strong> '\n",
    "            f'{escaped_text}'\n",
    "            '</div>'\n",
    "        )\n",
    "\n",
    "    formatted_html += '</div>'\n",
    "    return formatted_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "127b6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chats_to_pdf(list_of_chat_histories, filename):\n",
    "    combined_html = \"\"\n",
    "    for chat_history in list_of_chat_histories:\n",
    "        combined_html += format_single_chat(chat_history)\n",
    "    \n",
    "    # Generate PDF from the combined HTML content\n",
    "    pdfkit.from_string(combined_html, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95a35797",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_chats_to_pdf(resulting_dicts, \"./synthetic/synthetic_agent_sampler2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cb60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
