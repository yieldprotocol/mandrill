# The model to use in generation.  Available models: https://platform.openai.com/docs/models/continuous-model-upgrades
model: "gpt-4"
  
# OpenAI API key (if null, uses environment variable OPENAI_API_KEY)
openai_api_key: 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

# Optionally configure the OpenAI organization ID.
organization_id:

# Combined output file path.
output_path: instructions.jsonl

# Path to the default topics file.
topics_path: topics.txt

# Overwrite the output file, use with care!
overwrite: false

# Append to the output file.
append: true

# Embedding model, for calculating similarity between documents; probably best left as-is since the code is fairly specific to this one.
embedding_model: thenlper/gte-small
embedding_device: cpu
# If you have a GPU, set this to "cuda", e.g.:
# embedding_device: cuda

# Topic avoidance prompt string.
topic_avoidance: Avoid any tasks that would be related to climate change, green tech, renewable energy, DEI (diversity, equity, inclusion), sex and/or gender, religion, politics, social issues, race, ethnicity, artificial intelligence, baking/cooking, urban development, or any topic that you would likely not respond to, or any task which a language model would not be able to respond to, e.g. tasks about emotions, feelings, physical senses, etc.

# Regexes used to filter responses, mostly common words and phrases used in refusals.
response_filters:
  - "my programming"
  - "openai"
  - "language model"
  - "large language"
  - "as an? (ai|generative language|gpt|bot)"
  - "illegal and dangerous"
  - "i do(n't| not) (possess|have|exhibit) (personal|consciousness|subjective)"
  - "personal (feelings|thoughts|emotions|desires|experiences|goals|objective|belief)"
  - "(can('t| ?not)|w(on't|will not)|unable.?) (\\w+\\s)+(with (that|your)|your \\w+|provide)"
  - "my limitations"
  - "the limitations of my"
  - "my abilities"
  - "violates my"
  - "i (can('t| ?not)|w(on't|will not)|am (not |un)able.?).{0,30}(you are|you're|your )"
  - "please note that"
  - "flesch"

# Optionally limit the maximum number of tokens to use when generating instructions.
max_tokens:

# Minimum similarity score when checking for duplicates.
min_docsearch_score: 0.07

# Default OpenAI API request parameters.
api_params:
  temperature: 0.7
  top_p: 0.5
  frequency_penalty: 0.0
  presence_penalty: 2

# Topic generation prompt.
topic_prompt: Give me a numbered list of 20 completely random topics. {topic_avoidance}
topic_request_count: 20

# Default count per generator, if not specified.
default_count: 100

# Default batch size, if not specified.
default_batch_size: 10

# Default readability score hint: https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests
default_flesch: The output should be written in such a way as to have a Flesch-Kincaid readability score of 30 or lower - best understood by those with college education.  The response must not contain any notes or information about Flesch-Kincaid scores.

# Language.
language: English

# Individual instructor configurations.
instructors:

  ##################################################################################
  # BBH-Hard Chain-of-thought.
  bbh_hard:
    count: 50
    batch_size: 4
    min_docsearch_score: 0.15
    prompt_path: bbh_hard.txt

  ##################################################################################
  # AGIEval Chain-of-thought.
  agieval:
    count: 50
    batch_size: 2
    min_docsearch_score: 0.2
    prompt_path: agieval.txt

  ##################################################################################
  # Character cards - these aren't used directly, they are stored in output_dir, and
  # used by the chat instructor, stylized response, etc.
  character:
    api_params:
      temperature: 0.9
    count: 25
    batch_size: 1
    min_docsearch_score: 0.1
    seed_path: character_seeds
    output_dir: characters